{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "aacd9efd2e917f2085b49ad3eecd2bc8a974d0bb8b89bc48afae7fa44e9f517f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, LeakyReLU, Activation, Dropout, BatchNormalization, LeakyReLU, Concatenate\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics \n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    if batchnorm:\n",
    "        g =  BatchNormalization()(g, training=True)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    "\n",
    "def define_decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2DTranspose(n_filters, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    if dropout:\n",
    "        g = Dropout(0.4)(g, trainig=True)\n",
    "    g = Concatenate([g, skip_in])\n",
    "    g = Activation('relu')(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defing_generator(image_shape=[128, 128, 3]):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    content_image = Input(shape=image_shape)\n",
    "    style_image = Input(shape=image_shape)\n",
    "    # stack content and style images\n",
    "    stacked_layer = Concatenate()([content_image, style_image])\n",
    "    #encoder model\n",
    "    e1 = define_encoder_block(stacked_layer, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck layer\n",
    "    b = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_constraint=init)(e7)\n",
    "    b = Activation('relu')(b)\n",
    "    #decoder model\n",
    "    d1 = define_decoder_block(b, e7, 512)\n",
    "    d2 = define_decoder_block(d1, e6, 512)\n",
    "    d3 = define_decoder_block(d2, e5, 512)\n",
    "    d4 = define_decoder_block(d3, e4, 512, dropout=False)\n",
    "    d5 = define_decoder_block(d4, e3, 256, dropout=False)\n",
    "    d6 = define_decoder_block(d5, e2, 128, dropout=False)\n",
    "    d7 = define_decoder_block(d6, e1, 64, dropout=False)\n",
    "    #ouutput layer\n",
    "    g = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d7)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    model = Model(inputs=[content_image, style_image], outputs=out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_cnt_descriminator(image_shape=(128, 128, 3)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    #content image input\n",
    "    in_cnt_image = Input(shape=image_shape)\n",
    "    #transfer image input \n",
    "    in_tr_image = Input(shape=image_shape)\n",
    "    #concatnate image channel-wise\n",
    "    merged = Concatenate()([in_cnt_image, in_tr_image])\n",
    "    # c64\n",
    "    d = Conv2D(64, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c128\n",
    "    d = Conv2D(128, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c256\n",
    "    d = Conv2D(256, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c512\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c512\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    #define model\n",
    "    model = Model(inputs=[in_cnt_image, in_tr_image], outputs=patch_out)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_style_descrminator(image_size):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    input_img = Input(shape=image_size)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(input_img)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "    d = Conv2D(128, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "    d = Conv2D(256, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # flatten\n",
    "    flt = Flatten()(d)\n",
    "    # linear logits layer\n",
    "    output = Dense(1)(flt)\n",
    "    #build and compile the model\n",
    "    model = Model(inputs=input_img, outputs=output, name='style_descriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, dc_model, ds_model, image_shape):\n",
    "    for layer in dc_model:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    \n",
    "    for layer in ds_model:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    # input layer for GAN model\n",
    "    cnt_img = Input(shape=image_shape)\n",
    "    style_img = Input(shape=image_shape)\n",
    "    # generator model\n",
    "    gen_out = g_model([cnt_img, style_img])\n",
    "    # style descriminator model\n",
    "    dss_out = ds_model(style_img)\n",
    "    dst_out = ds_model(gen_out)\n",
    "    # content descriminator model\n",
    "    cnt_out = dc_model([cnt_img, gen_out])\n",
    "    model = Model(inputs=[cnt_img, style_img], outputs=[gen_out,  dss_out, dsc_out, cnt_out])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 76s 1us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16_feature_net = tf.keras.applications.VGG16(include_top=False, input_shape=(128, 128, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"vgg16\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n_________________________________________________________________\nblock1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n_________________________________________________________________\nblock1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n_________________________________________________________________\nblock1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n_________________________________________________________________\nblock2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n_________________________________________________________________\nblock2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n_________________________________________________________________\nblock2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n_________________________________________________________________\nblock3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n_________________________________________________________________\nblock3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n_________________________________________________________________\nblock3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n_________________________________________________________________\nblock3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n_________________________________________________________________\nblock4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n_________________________________________________________________\nblock4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n_________________________________________________________________\nblock4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n_________________________________________________________________\nblock5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n_________________________________________________________________\nblock5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n=================================================================\nTotal params: 14,714,688\nTrainable params: 14,714,688\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16_feature_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_style_descrminator(output_size,image_shape):\n",
    "    vgg16_feature_net = tf.keras.applications.VGG16(include_top=False, input_shape=image_shape)\n",
    "    for layer in vgg16_feature_net.layers:\n",
    "        layer.trainable = False\n",
    "    feature_map = vgg16_feature_net.output\n",
    "    x = Flatten()(feature_map)\n",
    "    x = Dropout(rate=0.5)(x)\n",
    "    x = Dense(512, activation='relu')\n",
    "    logits = Dense(output_size, use_bias=False)\n",
    "    model = Model(inputs=vgg16_feature_net.input, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'Flatten' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-809247189d57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdss_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdefine_style_descrminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-ea3315bc1802>\u001b[0m in \u001b[0;36mdefine_style_descrminator\u001b[1;34m(output_size, image_shape)\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfeature_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvgg16_feature_net\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Flatten' is not defined"
     ]
    }
   ],
   "source": [
    "dss_model = define_style_descrminator(64, (128, 128, 3))\n",
    "dss_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}