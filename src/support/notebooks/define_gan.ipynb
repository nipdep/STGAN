{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "aacd9efd2e917f2085b49ad3eecd2bc8a974d0bb8b89bc48afae7fa44e9f517f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import tensorflow as tf\n",
    "from numpy import load\n",
    "from numpy import zeros\n",
    "from numpy import ones\n",
    "from numpy.random import randint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Flatten, Dense, Conv2DTranspose, LeakyReLU, Activation, Dropout, BatchNormalization, LeakyReLU, Concatenate\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics \n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2D(n_filters, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    if batchnorm:\n",
    "        g =  BatchNormalization()(g, training=True)\n",
    "    g = LeakyReLU(alpha=0.2)(g)\n",
    "    return g\n",
    "\n",
    "def define_decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    g = Conv2DTranspose(n_filters, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "    g = BatchNormalization()(g, training=True)\n",
    "    if dropout:\n",
    "        g = Dropout(0.4)(g, trainig=True)\n",
    "    g = Concatenate([g, skip_in])\n",
    "    g = Activation('relu')(g)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def defing_generator(image_shape=[128, 128, 3]):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    content_image = Input(shape=image_shape)\n",
    "    style_image = Input(shape=image_shape)\n",
    "    # stack content and style images\n",
    "    stacked_layer = Concatenate()([content_image, style_image])\n",
    "    #encoder model\n",
    "    e1 = define_encoder_block(stacked_layer, 64, batchnorm=False)\n",
    "    e2 = define_encoder_block(e1, 128)\n",
    "    e3 = define_encoder_block(e2, 256)\n",
    "    e4 = define_encoder_block(e3, 512)\n",
    "    e5 = define_encoder_block(e4, 512)\n",
    "    e6 = define_encoder_block(e5, 512)\n",
    "    e7 = define_encoder_block(e6, 512)\n",
    "    # bottleneck layer\n",
    "    b = Conv2D(512, (4, 4), strides=(2, 2), padding='same', kernel_constraint=init)(e7)\n",
    "    b = Activation('relu')(b)\n",
    "    #decoder model\n",
    "    d1 = define_decoder_block(b, e7, 512)\n",
    "    d2 = define_decoder_block(d1, e6, 512)\n",
    "    d3 = define_decoder_block(d2, e5, 512)\n",
    "    d4 = define_decoder_block(d3, e4, 512, dropout=False)\n",
    "    d5 = define_decoder_block(d4, e3, 256, dropout=False)\n",
    "    d6 = define_decoder_block(d5, e2, 128, dropout=False)\n",
    "    d7 = define_decoder_block(d6, e1, 64, dropout=False)\n",
    "    #ouutput layer\n",
    "    g = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(d7)\n",
    "    out_image = Activation('tanh')(g)\n",
    "    model = Model(inputs=[content_image, style_image], outputs=out_image)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_cnt_descriminator(image_shape=(128, 128, 3)):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    #content image input\n",
    "    in_cnt_image = Input(shape=image_shape)\n",
    "    #transfer image input \n",
    "    in_tr_image = Input(shape=image_shape)\n",
    "    #concatnate image channel-wise\n",
    "    merged = Concatenate()([in_cnt_image, in_tr_image])\n",
    "    # c64\n",
    "    d = Conv2D(64, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c128\n",
    "    d = Conv2D(128, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c256\n",
    "    d = Conv2D(256, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c512\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # c512\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyRelu(alpha=0.2)(d)\n",
    "    # patch output\n",
    "    d = Conv2D(512, (4, 4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "    patch_out = Activation('sigmoid')(d)\n",
    "    #define model\n",
    "    model = Model(inputs=[in_cnt_image, in_tr_image], outputs=patch_out)\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_style_descrminator(image_size):\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "    input_img = Input(shape=image_size)\n",
    "    # C64\n",
    "    d = Conv2D(64, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(input_img)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "    d = Conv2D(128, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "    d = Conv2D(256, (4, 4), (4, 4), padding='SAME', kernel_initializer=init)(d)\n",
    "    d = BatchNormalization()(d)\n",
    "    d = LeakyReLU(alpha=0.2)(d)\n",
    "    # flatten\n",
    "    flt = Flatten()(d)\n",
    "    # linear logits layer\n",
    "    output = Dense(1)(flt)\n",
    "    #build and compile the model\n",
    "    model = Model(inputs=input_img, outputs=output, name='style_descriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_gan(g_model, dc_model, ds_model, image_shape):\n",
    "    for layer in dc_model:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    \n",
    "    for layer in ds_model:\n",
    "        if not isinstance(layer, BatchNormalization):\n",
    "            layer.trainable = False\n",
    "    # input layer for GAN model\n",
    "    cnt_img = Input(shape=image_shape)\n",
    "    style_img = Input(shape=image_shape)\n",
    "    # generator model\n",
    "    gen_out = g_model([cnt_img, style_img])\n",
    "    # style descriminator model\n",
    "    dss_out = ds_model(style_img)\n",
    "    dst_out = ds_model(gen_out)\n",
    "    # content descriminator model\n",
    "    cnt_out = dc_model([cnt_img, gen_out])\n",
    "    model = Model(inputs=[cnt_img, style_img], outputs=[gen_out,  dss_out, dsc_out, cnt_out])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}